# bb-python #
<span style="font-weight: bold">Цель</span> - научить ребят применять Python для анализа и обработки данных, решая практические задачи, которые возникают в работе инженера-нефтяника.

*Какие навыки будут получены в ходе прохождения курса?*

- Изучит базовые принципы при написании кода на Python
- Научится конструировать алгоритмы в парадигме нефтянного инжиниринга
- Научится экономить время для решения базовых задач геолога, петрофизика и разработчика
- Научится составлять скрипты-помощники, которые можно будет применять
- Освоит инструментарий для визуализации исходных и интерпретированных данных
- Ознакомится с некоторыми методами машинного обучения и попробует применить их на практике в реальными данными

Данный курс посвящен изучению основ языка программирования Python. Для эффективного использования материалов курса студенту не обязательно быть подготовленным в вопросах программирования, однако наличие каких-то познаний в этой области значительно упростит процесс обучения. Если же вы впервые начинаете программировать, то мы рекомендуем после прохождения курса вернуться в самое начало и еще раз пролистать все лекции - возможно некоторые вещи при первом прочтении были вам не совсем понятны, а после завершения курса станут очевидными.

При написании курса предполагалось, что он будет использоваться студентами инженерных специальностей, поэтому мы ожидаем, что читатель будет хорошо знаком с математическими понятиями. В примерах программ на языке Python могут использоваться алгоритмы из комплексной арифметики, линейной алгебры, математического анализа, теории вероятностей и других разделов высшей математики.

<details>
    <summary>Начала работы</summary>
    1. <span style="font-weight: bold">Создание environment</span>
    </br>
    В языке программирования Python "environment" означает набор переменных окружения, которые определяют, как программа будет работать на определенном компьютере. Это может включать в себя путь к установленным библиотекам и другим зависимостям, настройки компилятора, системные переменные и т.д. 
    Иными словами, это виртуальное ядро вашего проекта, в котором содержатся все необходимые библиотеки в тех версиях, которые будут реализовывать ваш код без сбоев и ошибок. Переключение между проектами лучше осуществлять со сменой environment.
    В зависимости от того, какая версия Python используется и какие библиотеки установлены, environment может оказывать значительное влияние на работу программы.
    </br>
    2. <span style="font-weight: bold">Установка VSCode</span> - это текстовый редактор с открытым исходным кодом, разработанный компанией Microsoft. Он позволяет создавать и редактировать код на различных языках программирования, а также предоставляет множество функций и расширений, которые облегчают процесс разработки или JupyterNotebook - это среда разработки, где сразу можно видеть результат выполнения кода и его отдельных фрагментов
    </br>
    3. <span style="font-weight: bold">Запустите Anaconda.Navigator</span>, перейдите во вкладку  Environment, нажмите кнопку Create , введите имя ядра, выберете версию Python для работы. 
    </br>
    4. <span style="font-weight: bold">Правила организации работы: создание рабочей директории</span>
    </br>
    Личный опыт показывает, что организация порядка в рабочей папки позволит лучше ориентироваться в рабочем проекте. Развитие вашего проекта сопровождается увеличением объема входных и выходных данных, числа рисунков, инструкций и прочего. Структурируйте инпуты/аутпуты сразу - ниже показан пример, как это сделать:
    5. <span style="font-weight: bold">Установка и импорт библиотек</span>
        *В рамках этого курса*, держите в голове мысль “Задачу, которую я пытаюсь решить сейчас, до меня уже решили!”.  Это значит, предполагаемые механизмы аналитических расчетов, способов визуализации, обработки и препроцессинга данных - уже реализованы в “питоновских“ библиотеках. Вам лишь остается решить задачу выбора подходящей библиотки и вызова из нее требуемой функции/метода/класса.
        Например, существует бибиотека *NumPy*. Вот что про нее говорит *ChatGPT*:
        *NumPy (Numerical Python) - это библиотека языка программирования Python, которая предоставляет полезные инструменты для работы с массивами, матрицами и другими типами данных, используемыми в научных вычислениях. В NumPy представлены функции для выполнения математических операций, линейной алгебры, обработки изображений и многое другое. Она является одной из основных библиотек для научных вычислений в Python.*
        Для установки библиотки можно воспользоваться следующим алгоритмом.
        - Откройте тетрадь в VSCode/JupyterNotebook.
        - Установите нужную библиотеку, используя команду *pip:*
        - Импортируйте библиотеку:
</details>
<details>
    <summary>Переменные  (Основы Python)</summary>
    1. <span style="font-weight: bold">Типы: integer, float, string, bool, complex</span>
    </br>
    **int** (целое число) - это тип данных, который представляет целые числа без запятых и дробей. Например, $5,$ $-10$, $1000$ и т.д. Они используются для записи количественных значений в программном коде.
    **float** (число с плавающей запятой) - это тип данных, который представляет вещественные числа. Они содержат запятую, что позволяет записывать дробные числа. Например, $3.14$, $-2.5$, $1000.0$ и т.д. Эти числа используются для более точных значений в программном коде.
    **str** (строка) - это тип данных для текстовых значений, которые содержат символы, цифры или пробелы. Они формируются путем заключения текстовых значений в кавычки. Например, $"hello world"$, $"123"$, $"python"$ и т.д. Строки используются для работы с текстом в программном коде.
    **bool** (булево значение) - это тип данных, который представляет логические значение $True$  или $False$. Они используются для выполнения проверок в программном коде. Например, $True$  or $False$, $1==1$ и т.д.
    complex (комплексное число) - это тип данных, который представляет комплексные числа. Они состоят из двух частей - действительной и мнимой. Они записываются в виде a + bi, где a и b - это числа. Эти числа используются для математических вычислений в программном коде. Например, $(3+2j)$, $(-2+4j)$ и т.д.
    2. <span style="font-weight: bold">Способы хранения данных</span>
    **dict, list, array**  — это базовые типы данных в Python, которые часто используются для хранения и обработки структурированных данных.
    - **dictionary** — это словарь, который содержит список слов или фраз. Словарь может содержать любое количество слов или фраз, а также дополнительные поля, такие как перевод на другой язык или дата добавления в словарь.
    - **list** — это список, который содержит элементы одного типа. Список может содержать только один элемент, но может быть бесконечным. Элементы списка могут быть любого типа, включая числа, строки, булевы значения и т.д.
    - **array** — это массив, который содержит элементы одного типа. Массив может содержать только один элемент, но может быть бесконечным. Элементы массива могут быть любого типа, включая числа, строки, булевы значения и т.д.
    Важно помнить, что типы данных в Python могут быть изменены с помощью методов класса `type()`. Например, метод `type()` для словаря возвращает тип данных, соответствующий его содержимому.
    Некторорые правила синтаксиса в Python:

    1. Программы на Python выполняются последовательно, то есть каждая строка кода выполняется в том порядке, в котором она написана.
    2. Python чувствителен к регистру символов, поэтому **`my_variable`** и **`My_Variable`** будут считаться разными переменными.
    3. Комментарии в Python начинаются со знака решетки (#) и продолжаются до конца строки. Комментарии игнорируются интерпретатором Python и используются для пояснения кода. Например:
        
        ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/524a9532-fee7-44c7-90ae-97fb86fb2d47/Untitled.png)
        
    4. Операторы (сложение ***+***, вычитание ***-*** , умножение ****,*** возведение в степень *****,*** деление **/**) в Python используются для выполнения операций над переменными и объектами, например, арифметические операторы для выполнения математических операций.
    5. Условные операторы (**if, elif, else**) в Python используются для выполнения логических действий в зависимости от того, выполняется ли определенное условие или нет.
    6. Циклы (**for**, **while**) в Python используются для повторного выполнения определенных операций до тех пор, пока выполняется определенное условие.
    7. Функции (**def (x)**)в Python используются для группировки определенного блока кода, который может быть вызван из другой части программы. Функции могут принимать аргументы и возвращать значения.
    Таблица базовых типов переменных Python:
    Операторы Python:
</details>
<details>
    <summary>Pandas/Numpy как база работы с файлами</summary>
    Для демонстрации нужны файлы формы XYZ, id,:features M:N,
    <details>
        <summary>Чтение данных</summary>
        Большая часть информации, с которой работают инженеры, хранится в табличном виде. Традиционно, формат файлов -это excel, csv, txt. Библиотеки Pandas и Numpy - это базовые     инструменты-интерфейсы для работы с файлами.
        Чтобы начать работу, сначала импортируйте библиотеку внтри рабочей тетрадки и выполните процедуру чтения файла, через вызов соответствующей функции бибилотеки pandas.
        Для понимания: вызов методов в библиотеки происходит через точку, т.е pd.название_метода(). Внутри круглых скобок указывают переменные, с которыми будет работать метод  или в зависимости от назначения метода, в круглых скобках можно настроить параметры. Если вы работаете в VSCode, то наведите мышкой на название метода и появится подсказка о том, как метод работает, что принимает на вход и что возвращает после его применения. Например (см.рисунок ниже). В случае JupyterNotebook подсказка будет всплывать, если поставить курсор в круглых скобках и нажать Shift+Tab
        По дефолту, метод воспринимает переданные в него переменные в порядке, как указанно в документации, т.е. в данном случае, первая переменная будет восприниматься как путь к файлу, вторая - как номер/имя листа в excel, с которым будет выполняться работа. Более детально структура методов(функций) будет разобрана в следующих главах Курса.
        Итак, давайте прочитаем файл, содержащий таблицу параметров для набора моделей.
        Задача: Создайте переменную df_short, которая будет содержать второй лист (short_table) файла if_features.xlsx. Заголовки столбцов содержатся в 1-ой строке.
        Документы формата txt могут также быть прочитанными с помощью библиотеки pandas. Для этого следует использовать метод pd.read_table(). В txt-файлах необходимо указывать параметр **sep** (сепаратор) для того, чтобы данные группировались по столбцам. Сепаратор может быть в виде запятой (sep = ‘,’), пробела ( sep = ‘ ’), точки  (sep = ‘.’), табуляции  (sep = '\t’) и др.
        В данном способе чтения, *df_txt* - это не таблица, а list, содержащий внутри себя строки. Такой формат пока что остается не работоспособным (так как со строками не работают математические операторы) и его нужно преобразовывать дальше. Это управжение мы проделаем в [следующих главах Курса](https://www.notion.so/bb-python-1428eaff9a2347a6b20a4fc41893663d).
        Совет: “Если ваш код применяется ежедневно и входные файлы приходят из разных источников, формулируйте и выставляейте требования к input’у таким образом, чтобы код не ломался”.
        Особенности чтения *.*txt* документов через *open*() - читаем строки как *float*() как *int*() 
        Вы уже заметили, что при чтении файлов через питоновские функции, мы будем работать со строками. Из рисунка ниже видно, что внутри листа df_txt есть 5 строк, разделенных запятыми. Внутри каждой строки переменная типа **[str](https://www.notion.so/bb-python-1428eaff9a2347a6b20a4fc41893663d).**
        Однако, очевидно то, что для этих данных более релевантен тип int или float.  Для этого можно воспользоваться библиотекой Numpy. Смысл в том, что изначальный лист df_txt преобразовывается в одномерный массив с конвертацией типа “строка - целое” через специальный параметр dtype.
    </details>
    <details>
        <summary>Способы обращения к табличным данным</summary>
        Если вы работаете с данными через pandas, то методы(функции) pd.iloc, pd.loc, pd.at будут проводниками к нужной строке, столбцу, ячейке данных. Например, перед вами стоит задача увидеть только нулевой столбец, содержащийся в переменной df_txt (см.рис.ниже). 
        Алгоритм действий будет следующий:
        - написать в ячейке имя переменной, содержащей табличные данные
        - *df_txt*
        - вызвать нужный метод, разделив имя переменной и метода точкой
        *df_txt**.**iloc*
        - указать в квадратных скобках идекс столбца, к которому надо обратиться. Причем, внутри скобок работат правило [строка , столбец]. Это значит, что все, находится левее запятой относится к ктрокам, а правее - ко столбцам.
        *df_txt.iloc[**: ,** 0]*
        Двоеточие слева от запятой означает запрос: “*Я хочу обратиться **ко значениям во всех строках** нулевого столбца*”. Если запись будет иметь вид *df_txt.iloc[**1:10 ,** 0]*, то это означает запрос: “*Я хочу обратиться к строкам с 1 по 9 (последняя строка не включается) в нулевом столбце”*. Если запись будет иметь вид *df_txt.iloc[**1:10 ,** **1:2**]*, то это означает запрос “*Я хочу обратиться к строкам с 1 по 9 в столбце №1*”.
        Если стоит задача обратиться к последнему/предпоследнему/предпредпоследнему столбцу и т.д, то обратная индексация поможет сделать это быстро. Например, два способа обращения к **последнему** стобцу будут эквиваленты: *df_txt.iloc[1:4, -1]* и *df_txt.iloc[1:4,2]*
        Или два способа обращения к предпоследнему стобцу будут эквиваленты: df_txt.iloc[1:4, -1] и  df_txt.iloc[1:4,2]
        Метод pd.loc работает аналогичным способом, но его вызов немного отличается. Например, ответом на запрос “Обратиться к строкам с 3 по 7 включительно в первом столбце” будет запись df_txt.loc[3:7][1]. Существенным отличием в данном методе является то, обращение к столбцу должно выполяться срого по его названию (как в данных), в то время как метод pd.iloc может выполнить тоже самое обращение через индекс столбца.
        Методы *iloc/loc* являются более гибкими, с точки зрения, что они могут показать нужные ячейки в таблице в некотором диапазоне строи и столбцов. Метод *pd.at[строка, столбец]* требует передавать на вход конкретные *ij*-координаты. **Совет**: “В циклах, когда необходимо процедурно заменять старые значения в таблице на новые, лучше применять метод *pd.at. Он меньше багует*”
        **Задача: Для датафрейма id-features.xlsx, посчитайте суммы, которые содержатся в строках с 34 по 49 для столбцов Corey_water, cos_teta и Fault_20. Для расчёта сумм, используейте внутренние методы pandas. Результирующий код должне быть написан в одну строку.**
        Теперь, когда вы понимаете, как работать с таблицами в pandas’е, нужно изучить основы обращения к данным в массивах Numpy. Лучший способ рассказать об этом, это проанализировать приведенные иллюстрации
        <details>
            <summary>Способы обращения к массивам Numpy</summary>
            Много картинок
        </details>
        <summary>Приёмы форматирования </summary>
           В зависимости от решаемой задачи, может потребоваться округление значений до определенного знака после запятой. Внутри Pandas и Numpy встроены свои методы, выполняющие округление данных. Однако, можно использовать внутренную функцию в Python. Например:
            - *df['ANI']***.round(3)** - для датафреймов. Цифра 3 указывает на желаемое количество знаков после запятой
            - *x.round(x,2)* - для массивов. Здесь x - массив numpy
            Приёмы фильтрации через задание условий оказываются очень полезными с точки зрения анализа данных. Для того, чтобы отобразить все строки датафрейма, где в столбце label содержится единица, следующий код:
            Фильтрацию датафрейма можно выполнять используя два или несколько условий. Например, запрос звучит так “Хочу увидеть данные, отфильтрованные по значение в столбце label = 2, при этом столбец Corey_O_W должен содержать значения больше нуля
            Проверить результаты можно, если построить гистограммы распределения:
            Задача: Отфильтруйте датафрейм таким образом, чтобы сэмплы(строки) содеражали значение целевой функции (’OF_PresME10_Wq_H’) меньше 2000. В получившемся массиве данных, начиная с 10 и заканчивая 120 строкой включительно с шагом равным 10, пройдитесь с первого до последного столбца с шагом равным 3 и выведите суммы в каждом из них. (Индексация начинается с нуля)
            Сортировка - полезный метод форматирования датафрейма. “Внутрипитоновская” функция *sorted()* принимает на вход любой массив данных и сортирует его по возрастанию/убыванию, в зависимости от выставленного параметра *reverse*
            Сортировка может быть одноуровневая, так и многоуровневая. Рассмотрим механизм сортировки в библиотеке pandas.
        <summary>Многокритериальное агрегирование через pd.groupby()</summary>
        Что это значит? Это значит, что сначала данные группируются по заданному фильтру, а после для каждой считается какая-нибудь статистическая функция (например, среднее значение или дисперсия).
        Например, существует датафрейм df, содержащий результаты процесса адаптация ГДМ в табличном виде, где каждая строка содержит вектор параметров i-ой модели
        Столбец label - содержит экспертные метки, по которым датасет можно разделить на три группы. Давайте вызовем фунцию df.groupby и одновременно применим функцию расчета среднего значения.
        Мы увидим, как исходных датафрейм сгруппировал данные по уникальным значениям в столбце label и для каждой группы посчитать среднее значение
        Однако, анализ данных может строиться на одновременной оценки нескольких статистик: среднего и медианного значений в группе, например. Для этого, в функционале библиотеки pandas предусмотрена функция pd.agg(), куда пользователь , в качестве аргумента функции, должен передать список имен-статистик. В общем виде запись будет выглядить так:
        Другая поставка задачи анализа данных может потребовать от нас сбора статистики для N количества фичей (имена столбцов). Например, “Покажи среднее и медианное значение в трех группах данных по фичам №10 и №17”. 
        Сначала мы создаем многоуровневый критерий в переменной ***dict_of_statistics  -*** это словарь, в котором ключи содержат имена фичей из исходного датафрей, а значения - списки с именами вычисляемых статистик .
        **Задача:** Для размеченных экспертных групп (label) в столбцах №14 и №22, отобразите медианное, среднее значения и дисперсию, округлив до 4 знаков после запятой. Затем, построчно, вычислите сумму и отобразите последнее значение
        <details>
            <summary>Полезные преобразования</summary>
            <details>
                <summary>pd.concat()</summary>
                Это встроенная функция библиотеки Pandas, которые объединяет (”конкатит”) несколько **датафреймов** в один. Синтаксис выглядит следующим образом:
                *Важно*: 1) Параметр *axis* регулирует механизм объединения датафреймов. Если *axis* = 0 - то датафреймы будут объединяться друг под другом (как строки), а если *axis* = 1 - то датафреймы будут объединяться “как столбцы”. 2) При данном методе объединения, имена столбцов и индексы строк не влияют на объединение датафреймов, если включен параметр i*gnore_index = True*. При этом, если имена столбцов были категориальными, то они заменятся индексами столбцов. 3) Датафреймы, подлежащие объединению, должны быть сложены в список (*квадратные скобки см. пример*)
                **Задача**: Для двух файлов **data.xlsx** и ****XYZ.txt,**** создайте один датафрейм, который будет содержать только первые 10 строк из каждого. Объединить датафреймы нужно по столбцам, сохранив исходные имена. Подсказка (*сохраните исходные имена датафреймов в списках и объедините спики через команду list_dfs = list_df1.extend(list_df2*)
                Аналог функции pd.conacat() в библиотеке Numpy - это np.stack().
                <summary>pd.pivot()</summary>
                Это метод, который преобразует табличные данные в матричный вид. Этот способ преобразования данных является часто встречаемым, когда вы будете работать с выгрузкой из спец.софрта нефтянников (Petrel). Синтаксис выглядит так:
                Важно: 1) Метод возращает прямоугольные матрицы (matrix.shape[0]≠ matrix.shape[1]. Если матица не квадратная, то в пустых ячейках будет содержаться NaN
                <summary>pd.merge()</summary>
                Метод будет для вас очень полезным, когда потребуется объединить два датафрейма разной формы (df.shape) по стобцу(ам) ключу. Т.е. представьте, что существует две талицы, содержащие различные характеристики объектов. При этом, первая таблица содержит данные по 100 объектам, а вторая по 23. И вам нужно собрать наиболее полный список известных характеристик в одном месте. Эту задачу можно реализовать через синтаксис:
                Важно: 1) Порядок датафреймов в методе будет регулировать итоговый вид таблицы. 2) Параметр on отвечает за ключ “мёрджинга” и данный ключ (с учётом синтаксиса) должен содержать как в правом, так и в левом датафрейме. 3) Ключей может быть несколько: чем их больше, тем более узкие границы пересечения между двумя датафреймами 4) При наличии одинаковых столбцов в левом и правом датафреймах, которые не являются ключами
                <summary>pd.sort_values()</summary>
                Метод позволяет выпонить сортировку данных по одному или нескольким ключевым столбцам датафрейма. Синтаксис выглядит следующим образом:
                Здесь, все три способа эквиваленты, отличие лишь в способе обращение к столбцу. Параметр ascending = False указывает на то, что сортировка будет происходит от наибольшего значения в столбце A к наименьшему. 
                **Задача**: Используя файл merge_sheets.xlsx, выполните сортировку первого листа по столбцу с индексом #3.
                Сотрировка может быть применена не только к числовым массивам данных, но также и к строковым. Здесь подбробно на примерах показан механизм, лежащий в основе сортировки строковых переменных
                <summary>pd.drop()</summary>
                Выбросить строки/столбцы данных из датафрейма можно через функцию pd.drop(). Синтаксис выглядит следующим образом:
                <summary>pd.fillna()</summary>
                Иногда, таблицы могут содержать пропуски данных, которые при чтении заполняются значением NaN - Not A Number. Причины пропуска данных не так важны в данном случае, но их наличие будет сказываться на работе некоторых алгоритмов. Поэтому эти пропуски можно заполнить какой-нибудь информации, исходя из понимания физических аспектов данных. Заполнить ячейки с пропускамми можно средними значениями, медианными или задать вручную:
            </details>
        </details>
    </details>  
</details>
